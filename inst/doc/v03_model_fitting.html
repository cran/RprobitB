<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>Model fitting</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>



<style type="text/css">
  code {
    white-space: pre;
  }
  .sourceCode {
    overflow: visible;
  }
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">
/* for pandoc --citeproc since 2.11 */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Model fitting</h1>



<p>This vignette<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> is a documentation of the estimation
procedure <code>fit_model()</code> in {RprobitB}.</p>
<div id="bayes-estimation-of-the-probit-model" class="section level2">
<h2>Bayes estimation of the probit model</h2>
<p>Bayes estimation of the probit model builds upon the work of <span class="citation">McCulloch and Rossi (<a href="#ref-McCulloch:1994" role="doc-biblioref">1994</a>)</span>, <span class="citation">Nobile (<a href="#ref-Nobile:1998" role="doc-biblioref">1998</a>)</span>, <span class="citation">Allenby and Rossi (<a href="#ref-Allenby:1998" role="doc-biblioref">1998</a>)</span>, and <span class="citation">Imai
and Dyk (<a href="#ref-Imai:2005" role="doc-biblioref">2005</a>)</span>.
A key ingredient is the concept of data augmentation, see <span class="citation">Albert and Chib (<a href="#ref-Albert:1993" role="doc-biblioref">1993</a>)</span>: The idea is to treat the latent
utilities <span class="math inline">\(U\)</span> in the model equation
<span class="math inline">\(U = X\beta + \epsilon\)</span> as additional
parameters. Then, conditional on <span class="math inline">\(U\)</span>,
the probit model constitutes a standard Bayesian linear regression
set-up. Its posterior distribution can be approximated by iteratively
drawing and updating each model parameter conditional on the other
parameters (the so-called Gibbs sampling approach).</p>
<p>A priori, we assume the following (conjugate) parameter
distributions:</p>
<ul>
<li><p><span class="math inline">\((s_1,\dots,s_C)\sim
D_C(\delta)\)</span>, where <span class="math inline">\(D_C(\delta)\)</span> denotes the <span class="math inline">\(C\)</span>-dimensional Dirichlet distribution with
concentration parameter vector <span class="math inline">\(\delta =
(\delta_1,\dots,\delta_C)\)</span>,</p></li>
<li><p><span class="math inline">\(\alpha\sim
\text{MVN}_{P_f}(\psi,\Psi)\)</span>, where <span class="math inline">\(\text{MVN}_{P_f}\)</span> denotes the <span class="math inline">\(P_f\)</span>-dimensional normal distribution with
mean <span class="math inline">\(\psi\)</span> and covariance <span class="math inline">\(\Psi\)</span>,</p></li>
<li><p><span class="math inline">\(b_c \sim
\text{MVN}_{P_r}(\xi,\Xi)\)</span>, independent for all <span class="math inline">\(c\)</span>,</p></li>
<li><p><span class="math inline">\(\Omega_c \sim
W^{-1}_{P_r}(\nu,\Theta)\)</span>, independent for all <span class="math inline">\(c\)</span>, where <span class="math inline">\(W^{-1}_{P_r}(\nu,\Theta)\)</span> denotes the
<span class="math inline">\(P_r\)</span>-dimensional inverse Wishart
distribution with <span class="math inline">\(\nu\)</span> degrees of
freedom and scale matrix <span class="math inline">\(\Theta\)</span>,</p></li>
<li><p>and <span class="math inline">\(\Sigma \sim
W^{-1}_{J-1}(\kappa,\Lambda)\)</span>.</p></li>
</ul>
<p>These prior distributions imply the following conditional posterior
distributions:</p>
<ul>
<li><p>The class weights are drawn from the Dirichlet distribution <span class="math display">\[\begin{equation}
(s_1,\dots,s_C)\mid \delta,z \sim D_C(\delta_1+m_1,\dots,\delta_C+m_C),
\end{equation}\]</span> where for <span class="math inline">\(c=1,\dots,C\)</span>, <span class="math inline">\(m_c=\#\{n:z_n=c\}\)</span> denotes the current
absolute class size.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p></li>
<li><p>Independently for all <span class="math inline">\(n\)</span>, we
update the allocation variables <span class="math inline">\((z_n)_n\)</span> from their conditional
distribution <span class="math display">\[\begin{equation}
\text{Prob}(z_n=c\mid s,\beta,b,\Omega )=\frac{s_c\phi_{P_r}(\beta_n\mid
b_c,\Omega_c)}{\sum_c s_c\phi_{P_r}(\beta_n\mid b_c,\Omega_c)}.
\end{equation}\]</span></p></li>
<li><p>The class means <span class="math inline">\((b_c)_c\)</span> are
updated independently for all <span class="math inline">\(c\)</span> via
<span class="math display">\[\begin{equation}
b_c\mid \Xi,\Omega,\xi,z,\beta \sim\text{MVN}_{P_r}\left( \mu_{b_c},
\Sigma_{b_c}  \right),
\end{equation}\]</span> where <span class="math inline">\(\mu_{b_c}=(\Xi^{-1}+m_c\Omega_c^{-1})^{-1}(\Xi^{-1}\xi
+m_c\Omega_c^{-1}\bar{b}_c)\)</span>, <span class="math inline">\(\Sigma_{b_c}=(\Xi^{-1}+m_c\Omega_c^{-1})^{-1}\)</span>,
<span class="math inline">\(\bar{b}_c=m_c^{-1}\sum_{n:z_n=c}
\beta_n\)</span>.</p></li>
<li><p>The class covariance matrices <span class="math inline">\((\Omega_c)_c\)</span> are updated independently
for all <span class="math inline">\(c\)</span> via <span class="math display">\[\begin{equation}
\Omega_c \mid \nu,\Theta,z,\beta,b \sim
W^{-1}_{P_r}(\mu_{\Omega_c},\Sigma_{\Omega_c}),
\end{equation}\]</span> where <span class="math inline">\(\mu_{\Omega_c}=\nu+m_c\)</span> and <span class="math inline">\(\Sigma_{\Omega_c}=\Theta^{-1} + \sum_{n:z_n=c}
(\beta_n-b_c)(\beta_n-b_c)&#39;\)</span>.</p></li>
<li><p>Independently for all <span class="math inline">\(n\)</span> and
<span class="math inline">\(t\)</span> and conditionally on the other
components, the utility vectors <span class="math inline">\((U_{nt:})\)</span> follow a <span class="math inline">\(J-1\)</span>-dimensional truncated multivariate
normal distribution, where the truncation points are determined by the
choices <span class="math inline">\(y_{nt}\)</span>. To sample from a
truncated multivariate normal distribution, we apply a sub-Gibbs
sampler, following the approach of <span class="citation">Geweke (<a href="#ref-Geweke:1998" role="doc-biblioref">1998</a>)</span>: <span class="math display">\[\begin{equation}
U_{ntj} \mid U_{nt(-j)},y_{nt},\Sigma,W,\alpha,X,\beta
\sim \mathcal{N}(\mu_{U_{ntj}},\Sigma_{U_{ntj}}) \cdot \begin{cases}
1(U_{ntj}&gt;\max(U_{nt(-j)},0) ) &amp; \text{if}~ y_{nt}=j\\
1(U_{ntj}&lt;\max(U_{nt(-j)},0) ) &amp; \text{if}~ y_{nt}\neq j
\end{cases},
\end{equation}\]</span> where <span class="math inline">\(U_{nt(-j)}\)</span> denotes the vector <span class="math inline">\((U_{nt:})\)</span> without the element <span class="math inline">\(U_{ntj}\)</span>, <span class="math inline">\(\mathcal{N}\)</span> denotes the univariate normal
distribution, <span class="math inline">\(\Sigma_{U_{ntj}} =
1/(\Sigma^{-1})_{jj}\)</span> and <span class="math display">\[\begin{equation}
\mu_{U_{ntj}} = W_{ntj}&#39;\alpha + X_{ntj}&#39;\beta_n -
\Sigma_{U_{ntj}} (\Sigma^{-1})_{j(-j)}   (U_{nt(-j)} -
W_{nt(-j)}&#39;\alpha - X_{nt(-j)}&#39; \beta_n ),
\end{equation}\]</span> where <span class="math inline">\((\Sigma^{-1})_{jj}\)</span> denotes the <span class="math inline">\((j,j)\)</span>th element of <span class="math inline">\(\Sigma^{-1}\)</span>, <span class="math inline">\((\Sigma^{-1})_{j(-j)}\)</span> the <span class="math inline">\(j\)</span>th row without the <span class="math inline">\(j\)</span>th entry, <span class="math inline">\(W_{nt(-j)}\)</span> and <span class="math inline">\(X_{nt(-j)}\)</span> the coefficient matrices <span class="math inline">\(W_{nt}\)</span> and <span class="math inline">\(X_{nt}\)</span>, respectively, without the <span class="math inline">\(j\)</span>th column.</p></li>
<li><p>Updating the fixed coefficient vector <span class="math inline">\(\alpha\)</span> is achieved by applying the
formula for Bayesian linear regression of the regressors <span class="math inline">\(W_{nt}\)</span> on the regressands <span class="math inline">\((U_{nt:})-X_{nt}&#39;\beta_n\)</span>, i.e. <span class="math display">\[\begin{equation}
\alpha \mid \Psi,\psi,W,\Sigma,U,X,\beta \sim
\text{MVN}_{P_f}(\mu_\alpha,\Sigma_\alpha),
\end{equation}\]</span> where <span class="math inline">\(\mu_\alpha =
\Sigma_\alpha (\Psi^{-1}\psi + \sum_{n=1,t=1}^{N,T} W_{nt} \Sigma^{-1}
((U_{nt:})-X_{nt}&#39;\beta_n) )\)</span> and <span class="math inline">\(\Sigma_\alpha = (\Psi^{-1} + \sum_{n=1,t=1}^{N,T}
W_{nt}\Sigma^{-1} W_{nt}^{&#39;} )^{-1}\)</span>.</p></li>
<li><p>Analogously to <span class="math inline">\(\alpha\)</span>, the
random coefficients <span class="math inline">\((\beta_n)_n\)</span> are
updated independently via <span class="math display">\[\begin{equation}
\beta_n \mid \Omega,b,X,\Sigma,U,W,\alpha \sim
\text{MVN}_{P_r}(\mu_{\beta_n},\Sigma_{\beta_n}),
\end{equation}\]</span> where <span class="math inline">\(\mu_{\beta_n}
= \Sigma_{\beta_n} (\Omega_{z_n}^{-1}b_{z_n} + \sum_{t=1}^{T} X_{nt}
\Sigma^{-1} (U_{nt:}-W_{nt}&#39;\alpha) )\)</span> and <span class="math inline">\(\Sigma_{\beta_n} = (\Omega_{z_n}^{-1} +
\sum_{t=1}^{T} X_{nt}\Sigma^{-1} X_{nt}^{&#39;} )^{-1}\)</span>
.</p></li>
<li><p>The error term covariance matrix <span class="math inline">\(\Sigma\)</span> is updated by means of <span class="math display">\[\begin{equation}
\Sigma \mid \kappa,\Lambda,U,W,\alpha,X,\beta \sim
W^{-1}_{J-1}(\kappa+NT,\Lambda+S), \\
\end{equation}\]</span> where <span class="math inline">\(S =
\sum_{n=1,t=1}^{N,T} \varepsilon_{nt} \varepsilon_{nt}&#39;\)</span> and
<span class="math inline">\(\varepsilon_{nt} = (U_{nt:}) -
W_{nt}&#39;\alpha - X_{nt}&#39;\beta_n\)</span>.</p></li>
</ul>
<div id="parameter-normalization" class="section level3">
<h3>Parameter normalization</h3>
<p>Samples obtained from the updating scheme described above lack
identification (except for <span class="math inline">\(s\)</span> and
<span class="math inline">\(z\)</span> draws), compare to the vignette
on the model definition. Therefore, subsequent to the sampling, the
following normalizations are required for the <span class="math inline">\(i\)</span>th updates in each iterations <span class="math inline">\(i\)</span>:</p>
<ul>
<li><p><span class="math inline">\(\alpha^{(i)} \cdot
\omega^{(i)}\)</span>,</p></li>
<li><p><span class="math inline">\(b_c^{(i)} \cdot
\omega^{(i)}\)</span>, <span class="math inline">\(c=1,\dots,C\)</span>,</p></li>
<li><p><span class="math inline">\(U_{nt}^{(i)} \cdot
\omega^{(i)}\)</span>, <span class="math inline">\(n =
1,\dots,N\)</span>, <span class="math inline">\(t =
1,\dots,T\)</span>,</p></li>
<li><p><span class="math inline">\(\beta_n^{(i)} \cdot
\omega^{(i)}\)</span>, <span class="math inline">\(n =
1,\dots,N\)</span>,</p></li>
<li><p><span class="math inline">\(\Omega_c^{(i)} \cdot
(\omega^{(i)})^2\)</span>, <span class="math inline">\(c=1,\dots,C\)</span>, and</p></li>
<li><p><span class="math inline">\(\Sigma^{(i)} \cdot
(\omega^{(i)})^2\)</span>,</p></li>
</ul>
<p>where either <span class="math inline">\(\omega^{(i)} =
\sqrt{\text{const} / (\Sigma^{(i)})_{jj}}\)</span> with <span class="math inline">\((\Sigma^{(i)})_{jj}\)</span> the <span class="math inline">\(j\)</span>th diagonal element of <span class="math inline">\(\Sigma^{(i)}\)</span>, <span class="math inline">\(1\leq j \leq J-1\)</span>, or alternatively <span class="math inline">\(\omega^{(i)} = \text{const} /
\alpha^{(i)}_p\)</span> for some coordinate <span class="math inline">\(1\leq p \leq P_f\)</span> of the <span class="math inline">\(i\)</span>th draw for the coefficient vector <span class="math inline">\(\alpha\)</span>. Here, <span class="math inline">\(\text{const}\)</span> is any positive constant
(typically 1). The preferences will be flipped if <span class="math inline">\(\omega^{(i)} &lt; 0\)</span>, which only is the
case if <span class="math inline">\(\alpha^{(i)}_p &lt; 0\)</span>.</p>
</div>
<div id="burn-in-and-thinning" class="section level3">
<h3>Burn-in and thinning</h3>
<p>The theory behind Gibbs sampling constitutes that the sequence of
samples produced by the updating scheme is a Markov chain with
stationary distribution equal to the desired joint posterior
distribution. It takes a certain number of iterations for that
stationary distribution to be approximated reasonably well. Therefore,
it is common practice to discard the first <span class="math inline">\(B\)</span> out of <span class="math inline">\(R\)</span> samples (the so-called burn-in period).
Furthermore, correlation between nearby samples should be expected. In
order to obtain independent samples, we consider only every <span class="math inline">\(Q\)</span>th sample when computing Gibbs sample
statistics like expectation and standard deviation. The independence of
the samples can be verified by computing the serial correlation and the
convergence of the Gibbs sampler can be checked by considering trace
plots, see below.</p>
</div>
</div>
<div id="the-fit_model-function" class="section level2">
<h2>The <code>fit_model()</code> function</h2>
<p>The Gibbs sampling scheme described above can be executed by applying
the function</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fit_model</span>(<span class="at">data =</span> data)</span></code></pre></div>
<p>where <code>data</code> must be an <code>RprobitB_data</code> object
(see the vignette about choice data). The function has the following
optional arguments:</p>
<ul>
<li><p><code>scale</code>: A character which determines the <a href="#parameter-normalization">utility scale</a>. It is of the form
<code>&quot;&lt;parameter&gt; := &lt;value&gt;&quot;</code>, where
<code>&lt;parameter&gt;</code> is either the name of a fixed effect or
<code>Sigma_&lt;j&gt;,&lt;j&gt;</code> for the <code>&lt;j&gt;</code>th
diagonal element of <code>Sigma</code>, and <code>&lt;value&gt;</code>
is the value of the fixed parameter (i.e. <span class="math inline">\(\text{const}\)</span> introduced <a href="#parameter-normalization">above</a>). Per default
<code>scale = &quot;Sigma\_1,1 := 1&quot;</code>, i.e. the first error-term
variance is fixed to 1.</p></li>
<li><p><code>R</code>: The number of iterations of the Gibbs sampler.
The default is <code>R = 10000</code>.</p></li>
<li><p><code>B</code>: The length of the burn-in period, i.e. a
non-negative number of samples to be discarded. The default is
<code>B = R/2</code>.</p></li>
<li><p><code>Q</code>: The thinning factor for the Gibbs samples,
i.e. only every <code>Q</code>th sample is kept. The default is
<code>Q = 1</code>.</p></li>
<li><p><code>print_progress</code>: A boolean, determining whether to
print the Gibbs sampler progress.</p></li>
<li><p><code>prior</code>: A named list of parameters for the prior
distributions (their default values are documented in the
<code>check_prior()</code> function):</p>
<ul>
<li><p><code>eta</code>: The mean vector of length <code>P_f</code> of
the normal prior for <code>alpha</code>.</p></li>
<li><p><code>Psi</code>: The covariance matrix of dimension
<code>P_f</code> x <code>P_f</code> of the normal prior for
<code>alpha</code>.</p></li>
<li><p><code>delta</code>: The concentration parameter of length 1 of
the Dirichlet prior for <code>s</code>.</p></li>
<li><p><code>xi</code>: The mean vector of length <code>P_r</code> of
the normal prior for each <code>b_c</code>.</p></li>
<li><p><code>D</code>: The covariance matrix of dimension
<code>P_r</code> x <code>P_r</code> of the normal prior for each
<code>b_c</code>.</p></li>
<li><p><code>nu</code>: The degrees of freedom (a natural number greater
than <code>P_r</code>) of the Inverse Wishart prior for each
<code>Omega_c</code>.</p></li>
<li><p><code>Theta</code>: The scale matrix of dimension
<code>P_r</code> x <code>P_r</code> of the Inverse Wishart prior for
each <code>Omega_c</code>.</p></li>
<li><p><code>kappa</code>: The degrees of freedom (a natural number
greater than <code>J-1</code>) of the Inverse Wishart prior for
<code>Sigma</code>.</p></li>
<li><p><code>E</code>: The scale matrix of dimension <code>J-1</code> x
<code>J-1</code> of the Inverse Wishart prior for
<code>Sigma</code>.</p></li>
</ul></li>
<li><p><code>latent_classes</code>: A list of parameters specifying the
number and the updating scheme of latent classes, see the vignette <a href="https://loelschlaeger.de/RprobitB/articles/v04_modeling_heterogeneity.html">on
modeling heterogeneity fitting</a>.</p></li>
</ul>
</div>
<div id="example" class="section level2">
<h2>Example</h2>
<p>In <a href="https://loelschlaeger.de/RprobitB/articles/v02_choice_data.html">the
previous vignette on choice data</a>, we introduced the Train data set
from the {mlogit} package <span class="citation">(<a href="#ref-Croissant:2020" role="doc-biblioref">Croissant
2020</a>)</span> that contains 2922 choices between two fictional train
route alternatives. First, we transform the travel <code>time</code>
from minutes to hours and the travel <code>price</code> from guilders to
euros:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;Train&quot;</span>, <span class="at">package =</span> <span class="st">&quot;mlogit&quot;</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>Train<span class="sc">$</span>price_A <span class="ot">&lt;-</span> Train<span class="sc">$</span>price_A <span class="sc">/</span> <span class="dv">100</span> <span class="sc">*</span> <span class="fl">2.20371</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>Train<span class="sc">$</span>price_B <span class="ot">&lt;-</span> Train<span class="sc">$</span>price_B <span class="sc">/</span> <span class="dv">100</span> <span class="sc">*</span> <span class="fl">2.20371</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>Train<span class="sc">$</span>time_A <span class="ot">&lt;-</span> Train<span class="sc">$</span>time_A <span class="sc">/</span> <span class="dv">60</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>Train<span class="sc">$</span>time_B <span class="ot">&lt;-</span> Train<span class="sc">$</span>time_B <span class="sc">/</span> <span class="dv">60</span></span></code></pre></div>
<p>The following lines fit a probit model that explains the chosen trip
alternatives (<code>choice</code>) by their <code>price</code>,
<code>time</code>, number of <code>change</code>s, and level of
<code>comfort</code> (the lower this value the higher the comfort). For
normalization, the first linear coefficient, the <code>price</code>, was
fixed to <code>-1</code>, which allows to interpret the other
coefficients as monetary values:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>form <span class="ot">&lt;-</span> choice <span class="sc">~</span> price <span class="sc">+</span> time <span class="sc">+</span> change <span class="sc">+</span> comfort <span class="sc">|</span> <span class="dv">0</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">prepare_data</span>(<span class="at">form =</span> form, <span class="at">choice_data =</span> Train)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>model_train <span class="ot">&lt;-</span> <span class="fu">fit_model</span>(</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> data,</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">scale =</span> <span class="st">&quot;price := -1&quot;</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>The estimated coefficients (using the mean of the Gibbs samples as a
point estimate) can be printed via</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(model_train)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;            Estimate   (sd)</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1   price     -1.00 (0.00)</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2    time    -25.90 (2.09)</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3  change     -4.82 (0.84)</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 comfort    -14.49 (0.86)</span></span></code></pre></div>
<p>and visualized via</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">coef</span>(model_train), <span class="at">sd =</span> <span class="dv">3</span>)</span></code></pre></div>
<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAwAAAAJACAMAAAANcPFkAAABR1BMVEUAAAAAADoAAGYAOjoAOmYAOpAAZmYAZpAAZrY6AAA6ADo6AGY6OgA6Ojo6OmY6OpA6ZmY6ZpA6ZrY6kLY6kNtNTU1NTW5NTY5Nbo5NbqtNjqtNjshmAABmADpmAGZmOgBmOmZmZgBmZmZmkJBmkLZmkNtmtpBmtttmtv9uTU1uTW5uTY5ubo5ubqtuq+SOTU2OTW6OTY6Obk2Obm6Ojk2Ojm6OyP+QOgCQOjqQZgCQZjqQZmaQkDqQkGaQkLaQtpCQttuQ27aQ2/+rbk2rbm6rjk2rq26rq46ryKur5P+2ZgC2Zjq2kDq2tpC2ttu225C229u22/+2///Ijk3I5KvI///bkDrbtmbbtpDb27bb29vb/7bb/9vb///kq27k5Kvk///r6+v/tmb/yI7/25D/27b/29v/5Kv//7b//8j//9v//+T///+FyqdJAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAZFUlEQVR4nO2c63/U6HmGBRtae7fpIWUgFNJNjwshYNi2pmm7TQIkqd1DurD2pk2hrPF2MNb//7l6dZiRxmOE7Wd45n7e6/6BPaPR6NIt65L0jmdclIRknMJ7BQjxDAKQrIMAJOsgAMk6CECyDgKQrIMAJOsgAMk6tgIcFLctF/evRbHxov5y8rHDHz6zRJFMYyvAbrFhuLSDotr36y9LHty/jADk4jEV4HDzu5ce2y2uPp+cdlJBAGIRUwH2L/9682rZ7ZxvblVH7m8/LYrf/7Is3z7a2C8uf1l+/XtFcemv0sxfbxaX/vJROrh387Tp7u5Wx/7Lf5a+POvNUj3tO4+rxVXTr5Zv/6Fa2meWFUhmsRSg2uPfPrryIp0J0lE7HbsPN6sdtbiU9tiPNosrL/aLOtXD7a2Ncj5Pk9ndngDzWQ6aG40A9dfCdtxB8oqlAGmPr69YGg12Lz97+ygdn3+zuZEO2VfTA9VJoNrFNypZLv2s/PZRkR7p5qnTuzu7BOovprLg67SodJY53Pzei3pphJwzlgJUe3xz3VPuV7tpunVYXxGlnbXa9Ztr9v/+93/crHb7g7QT1zvvfJ768d7dmQDzae2tshPgo7/4T8MCJL8YCtBcp6Qr9nqPbc4HTdI1SzopdPNs1IrUI4PePPVSendnAsynNRdXKbUw6Sqp+KMvT1sjQsZiKEB7Vd9c6lx5sVsfw4cCvLlV/OE//8dvb1kJUP7m01Y5Qs4VOwHaY/ybW+nb/qWf39roRsPzR5v76cKnfwk0GMT27vYugW7PHu1fAtX5r58wCibnjp0AzS5dXZakQ/nh5p83o+FqqFuNddMYoBFg40V6SfPKi8EguJ2nfnrvbn8QPFtMtfTD5Nh+fYr44xfl23+z/N0DySx2AuzOrmE20m7cXJgcdFdFjQDt65ZF2oFnL4PO5inb53d3578I60+bv4zavQx6Zck7JQh5r5gJcDh/HTPt+vvt+xcOq4v0jz6bXSClX2h952dpeFD/Iuyv69eMunm6JXV3e78Jns+SnpZuvPm02HhR/yLse+z/5NzxfTfom1tXx2ciZHXxEuBw83ery/ddxq/EN14CcPlO1iJul0BcvpN1CJ8II1kHAUjWQQCSdRCAZB0EIFkHAUjWQQCSdRCAZB0zAbo3ehYbhx+ffHvysmnLJ7b59svF2apv73rCey53MWm1F9+P9O0pHzE7WPbJm/7EkzP0V6Va7Nia7bcfC3qPWUcXeVoLMojt3wWqfxjvLcDokga3338RZ4Htbpx4R96pTz+HAGdbqze3bs9mfZ8S75rnrFs81+QpwG73hyTqWfeH70jyE6CbBQE+XFYiwBfNZ1bS5UX3tx7609JnJT/5p+Lyr6uLms32Ay7d9I9/Wk25nSZfbT5Bf3V4CdTOMF94PVP7ntL29gLs7aPuwzWz/X52o04nQPP0BXaLe3OruPRF/Ycomulp/Z91E1O628161cz0h8LSrlw/pV5sqjJs2qxBMy3NstGux9VlW3GhdLfIZlE14XbZxw2eS5ZmFQJspg98pZ1gY7Zz9ael//XHZ9o9u5vWTG/mSw/VFwTt7XImwMLC6wfbzwx3txdhaR12v5t2h+7N1wMB+hce9dP77HZR6TLpza30vZu+0XyaIU1sFtLc7tYrMSsLqmX1a1T/F5v2t8DgDLBkKy6WbhfZzFp0azrH9Z9LlmclAtyub9YXBO3eNZh2kHag2zMBdquf0OL09ND/vSj7Q99OgOHCDz+ZH+C62ydgnzx7+/dfVPtN8/j+4COY1UGyOwF0T++z+4uqdqvB9G5ielJ3e7Ze7b758eN+jVO2wGzaQICTW3Gx9EyA2/PSfVz/uWR5VjUGqL70d7Ru2kH90fh2p25mr/egxenNQwfNn0IZXgItLHy398ej29uLsOrIf/gHv/3TZ/Nj4fASqLt07z+9z064elFpv+tNn0+c3+7WK10Ddcfq+VOWb4Fh+7I3BljYioul55bNS/dxQ9XJsqxSgN6593QBDuoX/pYJ8ObWpce93WJBgPnCq6vv2XVufXsRVu3vBxtvH332aLYnDAWYHyNnTx+wewIMpi8VoFuvgyv/86gev/Sfch4BeltxsfQyAfo4rn7Gs0IBDnp/rmQw7WC+j7b7f7k4vX4o/fgOTjkD9Bc+OMu3lx99WLWkn9wu93/nB7OnzAQ4cZHQPn3A7l24DKZ3E2cLSjN06/XmBz+t1Oj2+IP5GWBxCyy2L4cC9Isull4mQB93wB+MGc0KBaj/EET7M5hP6w33Dj+e/aW3xelpn0xPPdw8RYBu4fWO1+1H7e1FWHM8P1j2+ct6XHzQPNA9/QS7nrZRj3EH07uJ6cnd7Xnp3ea1nsfdU9Jil2yBE+3LxshlW3GxdDvfUIAerv9csjwrFKB+Ee7S/Jg2m7Yxv7/b/RnEhen17lM9eOnn7QF9UYDZwg/mf1Wxu70Ia8bZs993Da6M0yyzq5Z2UYvs5pqoeZVzsE6nvQzaXNUVt7sq9VPSYpdsgdlazF8WK7tZF7fiidLNfAMB+rjBc8nS8F4gknUQgGQdBCBZBwFI1kEAknUQgGQdBCBZBwFI1kEAknXWUIBv5AEBKmQDQABJAoDRvOeejQCSBACjQQA/QIAK+gAE8AMEqKAPQAA/QIAK2QAQQJIAwAqAAJIEAFYABJAkALACIIAkAcBoGAT7AQJU0AcggB8gQAV9AAL4AQJU0AcggB8gQIVsAAggSQBgBUAASQIAKwACSBIAWAEQQJIAYDQMgv0AASroAxDADxCggj4AAfwAASroAxDADxCgQjYABJAkALACIIAkAYAVAAEkCQCsAAggSQAwGgbBfoAAFfQBCOAHCFBBH4AAfoAAFfQBCOAHCFAhGwACSBIAWAEQQJIAwAqAAJIEAFYABJAkABgNg2A/QIAK+gAE8AMEqKAPQAA/QIAK+gAE8AMEqJANAAEkCQCsAAggSQBgBUAASQIAKwACSBIAjIZBsB8gQAV9AAL4AQJU0AcggB8gQAV9AAL4AQJUyAaAAJIEAFYABJAkALACIIAkAYAVAAEkCQBGwyDYDxCggj4AAfwAASroAxDADxCggj4AAfwAASpkA0AASQIAKwACSBIAWAEQQJIAwAqAAJIEAKNhEOwHCFBBH4AAfoAAFfQBCOAHCFBBH4AAfoAAFbIBIIAkAYAVAAEkCQCsAAggSQBgBTiDANO7e9W/863NWWK8aYpisSMC5ACwHwR/kL2/tN40RXHCAATIAWAuwNHW5PpXd/eOn/5qMrn/uvrfTLKXwnTTFMVJAxAgB8BKzgDVv+MnN8vpnZv1+eD5/fLlze7hb96dIsOMbBKyyoxs/fML8HSnTP+PHuxU/8qjh+anAM4AAD4c4EICbE0mk2s751u/08MYAMCHA1xIAPujfwqvAgH4cICLCJDGAK9vvDrf+p2eddk060wAYAU4gwDHT5pXgeYCVNdA9ldAa7Np1pkAYDS8Gc4PEKCCPgAB/AABKugDEMAPEKCCPgAB/AABKmQDQABJAgArAAJIEgBYARBAkgDACoAAkgQAo2EQ7AcIUEEfgAB+gAAV9AEI4AcIUEEfgAB+gAAVsgEggCQBgBUAASQJAKwACCBJAGAFQABJAoDRMAj2AwSooA9AAD9AgAr6AATwAwSooA9AAD9AgArZABBAkgDACoAAkgQAVgAEkCQAsAIggCQBwGgYBPsBAlTQByCAHyBABX0AAvgBAlTQByCAHyBAhWwACCBJAGAFQABJAgArAAJIEgBYARBAkgBgNAyC/QABKugDEMAPEKCCPgAB/AABKugDEMAPEKBCNgAEkCQAsAIggCQBgBUAASQJAKwACCBJADAaBsF+gAAV9AEI4AcIUEEfgAB+gAAV9AEI4AcIUCEbAAJIEgBYARBAkgDACoAAkgQAVgAEkCQAGA2DYD9AgAr6AATwAwSooA9AAD9AgAr6AATwAwSokA0AASQJAKwACCBJAGAFQABJAgArAAJIEgCMhkGwHyBABX0AAvgBAlTQByCAHyBABX0AAvgBAlTIBoAAkgQAVgAEkCQAsAIggCQBgBUAASQJAEbDINgPEKCCPgAB/AABKugDEMAPEKCCPgAB/AABKmQDQABJAgArAAJIEgBYARBAkgDACoAAkgQAo2EQ7AcIUEEfgAB+gAAV9AEI4AcIUEEfgAB+gAAVsgEggCQBgBUAASQJAKwACCBJAGAFQABJAoDRMAj2AwSooA9AAD9AgAr6AATwAwSooA9AAD9AgArZABBAkgDACoAAkgQAVgAEkCQAsAIggCQBwGgYBPsBAlTQByCAHyBABX0AAvgBAlTQByCAHyBAhWwACCBJAGAFQABJAgArAAJIEgBYARBAkgBgNAyC/QABKugDEMAPEKCCPgAB/AABKugDEMAPEKBCNgAEkCQAsAIggCQBgBUAASQJAKwACCBJADAaBsF+gAAV9AGrE2B6d+/sTzpD9Ld9gApagKI4uR9zBvADBKggBSiKJQYYC3D08JeTazvl9MefX/+qOgMcbaV71dfr9mcDqW3vRADQS1EsM8B4EHy0dePV6+t70zvb6RLo+Ml2+frGq+f3y5c3Z0BCXNIKcLYnnV2A7fL46U66/q/+N8OAowfVSeCh+SlA6eDjRQDQy4c5A1Q7e/l8uxPg3qs0bWsySVdCxlHa9l4EAP0sHQOsQIATZwD7o3+K1LZ3IgAY5AO8CnS0dTNd9bcCpDFA9a0aA1TT3n893y9a296HAGA01gI8+Lv6VaBGgPmrQPZXQAG2fYAK+gBzAez39FOiv+0DVNAHIIAfIECFbAD8JliSAMAKgACSBABWAASQJACwAiCAJAHAaHg3qB8gQAV9AAL4AQJU0AcggB8gQAV9AAL4AQJUyAaAAJIEAFYABJAkALACIIAkAYAVAAEkCQBGwyDYDxCggj4AAfwAASroAxDADxCggj4AAfwAASpkA0AASQIAKwACSBIAWAEQQJIAwAqAAJIEAKNhEOwHCFBBH4AAfoAAFfQBCOAHCFBBH4AAfoAAFbIBIIAkAYAVAAEkCQCsAAggSQBgBUAASQKA0TAI9gMEqKAPQAA/QIAK+gAE8AMEqKAPQAA/QIAK2QAQQJIAwAqAAJIEAFYABJAkALACIIAkAcBoGAT7AQJU0AcggB8gQAV9AAL4AQJU0AcggB8gQIVsAAggSQBgBUAASQIAKwACSBIAWAEQQJIAYDQMgv0AASroAxDADxCggj4AAfwAASroAxDADxCgQjYABJAkALACIIAkAYAVAAEkCQCsAAggSQAwGgbBfoAAFfQBCOAHCFBBH4AAfoAAFfQBCOAHCFAhGwACSBIAWAEQQJIAwAqAAJIEAFYABJAkABgNg2A/QIAK+gAE8AMEqKAPQAA/QIAK+gAE8AMEqJANAAEkCQCsAAggSQBgBUAASQIAKwACSBIAjIZBsB8gQAV9AAL4AQJU0AcggB8gQAV9AAL4AQJUyAaAAJIEAFYABJAkALACIIAkAYAVAAEkCQBGwyDYDxCggj4AAfwAASroAxDADxCggj4AAfwAASpkA0AASQIAKwACSBIAWAEQQJIAwAqAAJIEAKNhEOwHCFBBH4AAfoAAFfQBCOAHCFBBH4AAfoAAFbIBIIAkAYAVAAEkCQCsAAggSQBgBUAASQKA0TAI9gMEqKAPQAA/QIAK+gAE8AMEqKAPQAA/QIAK2QAQQJIAwAqAAJIEAFYABJAkALACIIAkAcBoGAT7AQJU0AcggB8gQAV9wMoEOH4yuT+/N727d+YljER/23/ACkWxmkOY/g9hZQIMd3kEcCF0gKJYkQH6P4SLD4KPtibXdtLX63vl8dNfTSb3X1f/66nNxOmPP59M0g3brMumWWdCCyiKVRmg/0O4sADHT7bL1zdePb+fvh4/uVlO79xMB/x0zG8mTu9s984A35CLp1h9vCuuScYFaHbto4d75dGDneOnO2X6X92sprcT0xxcArkQOANYAd4hwL1XZaNBtecPBWgnIoAbgTHAaC48COYMsMYEXgUazYUFSGOAavduxwADAboxAAJ4EQCM5uIvgw5fBRoI0L4KlK6EnvAqkAMBwGj4TbAfIECFbAAIIEkAYAVAAEkCACsAAkgSAFgBEECSAGA0DIL9AAEq6AMQwA8QoII+AAH8AAEq6AMQwA8QoEI2AASQJACwAiCAJAGAFQABJAkArAAIIEkAMBoGwX6AABX0AQjgBwhQQR+AAH6AABX0AQjgBwhQIRsAAkgSAFgBEECSAMAKgACSBABWAASQJAAYDYNgP0CACvoABPADBKigD0AAP0CACvoABPADBKiQDQABJAkArAAIIEkAYAVAAEkCACsAAkgSAIyGQbAfIEAFfQAC+AECVNAHIIAfIEAFfQAC+AECVMgGgACSBABWAASQJACwAiCAJAGAFQABJAkARsMg2A8QoII+AAH8AAEq6AMQwA8QoII+AAH8AAEqZANAAEkCACsAAkgSAFgBEECSAMAKgACSBACjYRDsBwhQQR+AAH6AABX0AQjgBwhQQR+AAH6AABWyASCAJAGAFQABJAkArAAIIEkAYAVAAEkCgNEwCPYDBKigD0AAP0CACvoABPADBKigD0AAP0CACtkAEECSAMAKgACSBABWAASQJACwAiCAJAHAaBgE+wECVNAHIIAfIEAFfQAC+AECVNAHIIAfIECFbAAIIEkAYAVAAEkCACsAAkgSAFgBEECSAGA0DIL9AAEq6AMQwA8QoII+AAH8AAEq6AMQwA8QoEI2AASQJACwAiCAJAGAFQABJAkArAAIIEkAMBoGwX6AABX0AQjgBwhQQR+AAH6AABX0AQjgBwhQIRsAAkgSAFgBEECSAMAKgACSBABWAASQJAAYDYNgP0CACvoABPADBKigD0AAP0CACvoABPADBKiQDQABJAkArAAIIEkAYAVAAEkCACsAAkgSAIyGQbAfIEAFfQAC+AECVNAHIIAfIEAFfQAC+AECVMgGgACSBABWAASQJACwAiCAJAGAFQABJAkARsMg2A8QoII+AAH8AAEq6AMQwA8QoII+AAH8AAEqZAMYE2B6d+/Cq3LGrMumWWdCBEBRrPToiwB+gAAVVg8oitUacHEBjrYm13amd/92MtmuRLiTvk3v/aK+Vz30/b/ZSd+u2/uh/8MNUGH1l+jFig24sADHT7bL1zf+98796uurowc76WQwbe6Vz6tv13bSt5c3Z0CSd4qV52yr8+6HxwVoLn7S1/Yy6OjhXnuvulUeP91JVqSbxtE/ugWooH8GuPCrQNN7r8qeAM8n1eVOey89lATYmkyqqySb9Z1H/4cboIL+GODiAvTPAEdb2/WePzwD2B/9U/R/uAEq6L8KdGEB0hhgever9pifvv1opzsfzMcAaURgHP0fboAK2QDGXwVqdvmXk8n3P9/u7lUP/cnTnWYOm9XtZV02zToTAFgBzn0WWt0vCNZl06wzAYAV4FwCHD9ZxeC3y7psmnUmALAC8F4gSQKA0fBmOD9AgAr6AATwAwSooA9AAD9AgAr6AATwAwSokA0AASQJAKwACCBJAGAFQABJAgArAAJIEgCMhkGwHyBABX0AAvgBAlTQByCAHyBABX0AAvgBAlTIBoAAkgQAVgAEkCQAsAIggCQBgBUAASQJAEbDINgPEKCCPgAB/AABKugDEMAPEKCCPgAB/AABKmQDQABJAgArAAJIEgBYARBAkgDACoAAkgQAo2EQ7AcIUEEfgAB+gAAV9AEI4AcIUEEfgAB+gAAVsgEggCQBgBUAASQJAKwACCBJAGAFQABJAoDRMAj2AwSooA9AAD9AgAr6AATwAwSooA9AAD9AgArZABBAkgDACoAAkgQAVgAEkCQAsAIggCQBwGgYBPsBAlTQByCAHyBABX0AAvgBAlTQByCAHyBAhWwACCBJAGAFQABJAgArAAJIEgBYARBAkgBgNAyC/QABKugDEMAPEKCCPgAB/AABKugDEMAPEKBCNgAEkCQAsAIggCQBgBUAASQJAKwACCBJADAaBsF+gAAV9AEI4AcIUEEfgAB+gAAV9AG6AhDy4YIAJOsgAMk6CECyDgKQrIMAJOsgAMk6CECyDgKQrLNmAryeTK7vleXR1uTGK+91OWemdyaTbe0K5fSu+A/h/dd9vQRIG/7lzfL4yXb6JpmjBzvl9Ec7yhWqw1B1FFJucIZ1Xy8BUioJjh7uNQchwbxO2/35tnKF59f+pVpz5QZnWPf1E6Ayd3rvVX0kVU217toV0s6j3OAM675uAkzvXNspX9/Q3fZlOgHfF6+QBFBucIZ1Xx8Bnk8m9VWb8OGzqXC0df9Mx6B1SvtD4AzgGe0L6Ooctl2e6Sp0DTNlDOCT9tSVriFUX4Bo9v9SuUIjgHKDM6z7eglQvpxMqjGA8kvQVYNJ+kWAcAV+D0BILkEAknUQgGQdBCBZBwFI1kEAknUQgGQdBCBZBwFI1kEAknUQgGQdBCBZBwFI1kEAknUQgGQdBCBZBwFI1kEAknUQgGQdBCBZBwFI1kEAknUQgGQdBCBZBwFI1kEAknUQgGSd/wcKxT1lxT3q9wAAAABJRU5ErkJggg==" width="75%" style="display: block; margin: auto;" /></p>
<p>The results indicate that the deciders value one hour travel time by
about 25€, an additional change by 5€, and a more comfortable class by
14€.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></p>
</div>
<div id="checking-the-gibbs-samples" class="section level2">
<h2>Checking the Gibbs samples</h2>
<p>The Gibbs samples are saved in list form in the
<code>RprobitB_fit</code> object at the entry
<code>&quot;gibbs_samples&quot;</code>, i.e.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(model_train<span class="sc">$</span>gibbs_samples, <span class="at">max.level =</span> <span class="dv">2</span>, <span class="at">give.attr =</span> <span class="cn">FALSE</span>)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; List of 2</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ gibbs_samples_raw:List of 2</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   ..$ alpha: num [1:1000, 1:4] -0.000713 -0.022961 -0.031988 -0.036215 -0.03571 ...</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   ..$ Sigma: num [1:1000, 1] 1.05 1.1 1.03 1.02 1.01 ...</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ gibbs_samples_nbt:List of 2</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   ..$ alpha: num [1:500, 1:4] -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 ...</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   ..$ Sigma: num [1:500, 1] 617 611 626 552 734 ...</span></span></code></pre></div>
<p>This object contains 2 elements:</p>
<ul>
<li><p><code>gibbs_samples_raw</code> is a list of the raw samples from
the Gibbs sampler,</p></li>
<li><p>and <code>gibbs_samples_nbt</code> are the Gibbs samples used for
parameter estimates, i.e. the normalized and thinned Gibbs samples after
the burn-in.</p></li>
</ul>
<p>Calling the summary function on the estimated
<code>RprobitB_fit</code> object yields additional information about the
Gibbs samples <code>gibbs_samples_nbt</code>. You can specify a list
<code>FUN</code> of functions that compute any point estimate of the
Gibbs samples<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>, for example</p>
<ul>
<li><p><code>mean</code> for the arithmetic mean,</p></li>
<li><p><code>stats::sd</code> for the standard deviation,</p></li>
<li><p><code>R_hat</code> for the Gelman-Rubin statistic <span class="citation">(<a href="#ref-Gelman:1992" role="doc-biblioref">Gelman
and Rubin 1992</a>)</span> <a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a>,</p></li>
<li><p>or custom statistics like the absolute difference between the
median and the mean.</p></li>
</ul>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model_train, </span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>        <span class="at">FUN =</span> <span class="fu">c</span>(<span class="st">&quot;mean&quot;</span>        <span class="ot">=</span> mean, </span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;sd&quot;</span>          <span class="ot">=</span> stats<span class="sc">::</span>sd, </span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;R^&quot;</span>          <span class="ot">=</span> R_hat,</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;custom_stat&quot;</span> <span class="ot">=</span> <span class="cf">function</span>(x) <span class="fu">abs</span>(<span class="fu">mean</span>(x) <span class="sc">-</span> <span class="fu">median</span>(x))</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>       )</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Probit model</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Formula: choice ~ price + time + change + comfort | 0 </span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; R: 1000, B: 500, Q: 1</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Level: Utility differences with respect to alternative &#39;B&#39;.</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Scale: Coefficient of effect &#39;price&#39; (alpha_1) fixed to -1.</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Gibbs sample statistics</span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                mean           sd           R^  custom_stat</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  alpha</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                                                           </span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      1        -1.00         0.00         1.00         0.00</span></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      2       -25.90         2.09         1.04         0.07</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      3        -4.82         0.84         1.00         0.02</span></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      4       -14.49         0.86         1.00         0.02</span></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Sigma</span></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                                                           </span></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    1,1       661.69        59.21         1.03         7.30</span></span></code></pre></div>
<p>Calling the <code>plot</code> method with the additional argument
<code>type = &quot;trace&quot;</code> plots the trace of the Gibbs samples
<code>gibbs_samples_nbt</code>:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">1</span>))</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_train, <span class="at">type =</span> <span class="st">&quot;trace&quot;</span>)</span></code></pre></div>
<p><img src="data:image/png;base64,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" width="75%" style="display: block; margin: auto;" /></p>
<p>Additionally, we can visualize the serial correlation of the Gibbs
samples via the argument <code>type = &quot;acf&quot;</code>. The boxes in the
top-right corner state the total sample size TSS (here <code>R</code> -
<code>B</code> = 10000 - 5000 = 5000), the effective sample size ESS,
and the factor by which TSS is larger than ESS.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>))</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_train, <span class="at">type =</span> <span class="st">&quot;acf&quot;</span>)</span></code></pre></div>
<p><img src="data:image/png;base64,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" width="75%" style="display: block; margin: auto;" /></p>
<p>Here, the effective sample size is the value <span class="math inline">\(\text{TSS} / (1 + \sum_{k\geq 1} \rho_k)\)</span>,
where <span class="math inline">\(\rho_k\)</span> is the auto
correlation between the chain offset by <span class="math inline">\(k\)</span> positions. The auto correlations are
estimated via the <code>stats::acf()</code> function.</p>
</div>
<div id="model-transformation-after-estimation" class="section level2">
<h2>Model transformation after estimation</h2>
<p>The <code>transform</code> method can be used to transform an
<code>RprobitB_fit</code> object in three ways:</p>
<ol style="list-style-type: decimal">
<li>change the length <code>B</code> of the burn-in period, for
example</li>
</ol>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>model_train <span class="ot">&lt;-</span> <span class="fu">transform</span>(model_train, <span class="at">B =</span> <span class="dv">1</span>)</span></code></pre></div>
<ol start="2" style="list-style-type: decimal">
<li>change the thinning factor <code>Q</code> of the Gibbs samples, for
example</li>
</ol>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>model_train <span class="ot">&lt;-</span> <span class="fu">transform</span>(model_train, <span class="at">Q =</span> <span class="dv">100</span>)</span></code></pre></div>
<ol start="3" style="list-style-type: decimal">
<li>or change the model normalization <code>scale</code>, for
example</li>
</ol>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>model_train <span class="ot">&lt;-</span> <span class="fu">transform</span>(model_train, <span class="at">scale =</span> <span class="st">&quot;Sigma_1 := 1&quot;</span>)</span></code></pre></div>
</div>
<div id="references" class="section level2 unnumbered">
<h2 class="unnumbered">References</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Albert:1993" class="csl-entry">
Albert, J. H., and S. Chib. 1993. <span>“Bayesian Analysis of Binary and
Polychotomous Response Data.”</span> <em>Journal of the American
Statistical Association</em> 88. <a href="https://doi.org/10.2307/2290350">https://doi.org/10.2307/2290350</a>.
</div>
<div id="ref-Allenby:1998" class="csl-entry">
Allenby, G. M., and P. Rossi. 1998. <span>“Marketing Models of Consumer
Heterogeneity.”</span> <em>Journal of Econometrics</em> 89. <a href="https://doi.org/10.1016/S0304-4076(98)00055-4">https://doi.org/10.1016/S0304-4076(98)00055-4</a>.
</div>
<div id="ref-Croissant:2020" class="csl-entry">
Croissant, Y. 2020. <span>“Estimation of Random Utility Models in r: The
Mlogit Package.”</span> <em>Journal of Statistical Software</em> 95
(11). <a href="https://doi.org/10.18637/jss.v095.i11">https://doi.org/10.18637/jss.v095.i11</a>.
</div>
<div id="ref-Gelman:1992" class="csl-entry">
Gelman, A., and D. B. Rubin. 1992. <span>“Inference from Iterative
Simulation Using Multiple Sequences.”</span> <em>Statistical
Science</em> 7 (4). <a href="https://doi.org/10.1214/ss/1177011136">https://doi.org/10.1214/ss/1177011136</a>.
</div>
<div id="ref-Geweke:1998" class="csl-entry">
Geweke, J. 1998. <span>“Efficient Simulation from the Multivariate
Normal and Student-t Distributions Subject to Linear Constraints and the
Evaluation of Constraint Probabilities.”</span> <em>Computing Science
and Statistics</em> 23.
</div>
<div id="ref-Imai:2005" class="csl-entry">
Imai, K., and D. A. van Dyk. 2005. <span>“A Bayesian Analysis of the
Multinomial Probit Model Using Marginal Data Augmentation.”</span>
<em>Journal of Econometrics</em> 124.
</div>
<div id="ref-McCulloch:1994" class="csl-entry">
McCulloch, R., and P. Rossi. 1994. <span>“An Exact Likelihood Analysis
of the Multinomial Probit Model.”</span> <em>Journal of
Econometrics</em> 64. <a href="https://doi.org/10.1016/0304-4076(94)90064-7">https://doi.org/10.1016/0304-4076(94)90064-7</a>.
</div>
<div id="ref-Nobile:1998" class="csl-entry">
Nobile, A. 1998. <span>“A Hybrid Markov Chain for the Bayesian Analysis
of the Multinomial Probit Model.”</span> <em>Statistics and
Computing</em> 8. <a href="https://doi.org/10.1023/A:1008905311214">https://doi.org/10.1023/A:1008905311214</a>.
</div>
</div>
</div>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p>This vignette is built using R 4.2.1 with the {RprobitB}
1.1.1 package.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>Mind that the model is invariant to permutations of the
class labels <span class="math inline">\(1,\dots,C\)</span>. For that
reason, we accept an update only if the ordering <span class="math inline">\(s_1&gt;\dots&gt;s_C\)</span> holds, thereby
ensuring a unique labeling of the classes.<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>These results are consistent with the ones that are
presented <a href="https://cran.r-project.org/package=mlogit/vignettes/c5.mxl.html#train">in
a vignette of the mlogit package</a> on the same data set but using the
logit model.<a href="#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>Use the function <code>point_estimates()</code> to
access the Gibbs sample statistics as an <code>RprobitB_parameter</code>
object.<a href="#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>A Gelman-Rubin statistic close to 1 indicates that the
chain of Gibbs samples converged to the stationary distribution.<a href="#fnref5" class="footnote-back">↩︎</a></p></li>
</ol>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
